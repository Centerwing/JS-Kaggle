{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Mainly for model training\n","\n","Depending on the size of your training set, you will need an [inference notebook](https://www.kaggle.com/code/regisvargas/inference-jane-street-a-beginner-s-notebook)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T01:34:52.337108Z","iopub.status.busy":"2024-11-18T01:34:52.336543Z","iopub.status.idle":"2024-11-18T01:36:11.435352Z","shell.execute_reply":"2024-11-18T01:36:11.433714Z","shell.execute_reply.started":"2024-11-18T01:34:52.337044Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","# Initialize a list to hold samples from each file\n","samples = []\n","# Load a sample from each file\n","for i in range(10):\n","    file_path = f\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet/partition_id={i}/part-0.parquet\"\n","    chunk = pd.read_parquet(file_path)\n","    \n","    # Take a sample of the data (adjust sample size as needed)\n","    sample_chunk = chunk.sample(n=500000, random_state=42)  # For example, 100 rows\n","    samples.append(sample_chunk)\n","# Concatenate all samples into one DataFrame if needed\n","sample_df = pd.concat(samples, ignore_index=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T01:36:11.439146Z","iopub.status.busy":"2024-11-18T01:36:11.438566Z","iopub.status.idle":"2024-11-18T01:36:11.487786Z","shell.execute_reply":"2024-11-18T01:36:11.486503Z","shell.execute_reply.started":"2024-11-18T01:36:11.439098Z"},"trusted":true},"outputs":[],"source":["sample_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# Prepare data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T01:36:11.490072Z","iopub.status.busy":"2024-11-18T01:36:11.489558Z","iopub.status.idle":"2024-11-18T01:36:21.018821Z","shell.execute_reply":"2024-11-18T01:36:21.017189Z","shell.execute_reply.started":"2024-11-18T01:36:11.490012Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","# Separate features and responders\n","features = sample_df.filter(regex='^feature_')\n","responders = sample_df.filter(regex='^responder_')\n","weights = sample_df['weight']\n","# Convert to numpy arrays for TensorFlow\n","X = features.values  # Features for input\n","#y = responders.values  # Responders for output\n","# Assuming you have a DataFrame `y_train` with all responders\n","y = responders[['responder_6']].values  # Keep only responder_6\n","X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n","y = np.nan_to_num(y, nan=0.0, posinf=0.0, neginf=0.0)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T01:36:21.021623Z","iopub.status.busy":"2024-11-18T01:36:21.020786Z","iopub.status.idle":"2024-11-18T01:36:21.026936Z","shell.execute_reply":"2024-11-18T01:36:21.02567Z","shell.execute_reply.started":"2024-11-18T01:36:21.021574Z"},"trusted":true},"outputs":[],"source":["Is_keras = False"]},{"cell_type":"markdown","metadata":{},"source":["# XGBoost\n","\n","See [Feature engineering, xgboost](https://www.kaggle.com/code/dlarionov/feature-engineering-xgboost#Part-2,-xgboost) for details."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T01:36:21.031198Z","iopub.status.busy":"2024-11-18T01:36:21.03069Z","iopub.status.idle":"2024-11-18T01:36:26.89436Z","shell.execute_reply":"2024-11-18T01:36:26.893149Z","shell.execute_reply.started":"2024-11-18T01:36:21.03113Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","X_train, X_val, y_train, y_val, weights_train, weights_val = train_test_split(\n","    X, y, weights, test_size=0.2, random_state=42\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T01:36:26.896989Z","iopub.status.busy":"2024-11-18T01:36:26.896068Z","iopub.status.idle":"2024-11-18T01:36:26.904948Z","shell.execute_reply":"2024-11-18T01:36:26.903595Z","shell.execute_reply.started":"2024-11-18T01:36:26.896929Z"},"trusted":true},"outputs":[],"source":["# Define a learning rate schedule\n","def learning_rate_scheduler_xgb(epoch):\n","    initial_rate = 0.3\n","    decay_rate = 0.999\n","    return initial_rate * (decay_rate ** (np.log(epoch)))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T01:36:26.907228Z","iopub.status.busy":"2024-11-18T01:36:26.906716Z","iopub.status.idle":"2024-11-18T01:48:07.295923Z","shell.execute_reply":"2024-11-18T01:48:07.294493Z","shell.execute_reply.started":"2024-11-18T01:36:26.907146Z"},"trusted":true},"outputs":[],"source":["from xgboost import XGBRegressor\n","# Create an XGBoost model\n","model_xgb = XGBRegressor(\n","    n_estimators=1000,\n","    learning_rate=learning_rate_scheduler_xgb,\n","    max_depth=8,\n","    random_state=42\n",")\n","# Fit the model with sample weights and validation dataset\n","model_xgb.fit(\n","    X_train,\n","    y_train,\n","    sample_weight=weights_train,\n","    eval_set=[(X_train, y_train), (X_val, y_val)],\n","    sample_weight_eval_set=[weights_train, weights_val],\n","    eval_metric='rmse',\n","    early_stopping_rounds=10,\n","    verbose=True\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Build the Autoencoder Model"]},{"cell_type":"markdown","metadata":{},"source":["Gradient Centralization for Better Training Performance\n","\n","See https://keras.io/examples/vision/gradient_centralization/ for details. "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T01:48:07.29831Z","iopub.status.busy":"2024-11-18T01:48:07.297872Z","iopub.status.idle":"2024-11-18T01:48:07.409151Z","shell.execute_reply":"2024-11-18T01:48:07.407927Z","shell.execute_reply.started":"2024-11-18T01:48:07.298266Z"},"trusted":true},"outputs":[],"source":["from keras.optimizers import RMSprop\n","class GCRMSprop(RMSprop):\n","    def get_gradients(self, loss, params):\n","        # We here just provide a modified get_gradients() function since we are\n","        # trying to just compute the centralized gradients.\n","        grads = []\n","        gradients = super().get_gradients()\n","        for grad in gradients:\n","            grad_len = len(grad.shape)\n","            if grad_len > 1:\n","                axis = list(range(grad_len - 1))\n","                grad -= ops.mean(grad, axis=axis, keep_dims=True)\n","            grads.append(grad)\n","        return grads\n","optimizer = GCRMSprop(learning_rate=1e-4)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T01:48:07.411152Z","iopub.status.busy":"2024-11-18T01:48:07.410754Z","iopub.status.idle":"2024-11-18T01:48:07.507935Z","shell.execute_reply":"2024-11-18T01:48:07.506764Z","shell.execute_reply.started":"2024-11-18T01:48:07.411109Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.regularizers import l2\n","# Define the number of input and output nodes\n","input_dim = X.shape[1]  # Number of features (79)\n","output_dim = y.shape[1]  # Number of responders (9)\n","# Define the model\n","model = models.Sequential([\n","    layers.Input(shape=(input_dim,)), # Input layer\n","    layers.LayerNormalization(),\n","   # layers.BatchNormalization(),\n","  #  layers.Dense(128, activation='relu'),\n","  #  layers.Dropout(0.2),\n","    layers.Dense(64, activation='linear'),  # Encoder\n","    layers.Dense(32, activation='linear'),  # Bottleneck layer (compression)\n","    layers.Dense(64, activation='linear'),  # Decoder\n","#    layers.Dense(128, activation='relu'), \n"," #   layers.Dropout(0.2),\n","    layers.Dense(output_dim, activation='linear', kernel_regularizer=l2(0.001))  # Output layer for responders\n","])\n","model.compile(optimizer=\"adam\", loss='mse')"]},{"cell_type":"markdown","metadata":{},"source":["# Train Autoencoder Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T01:48:07.510554Z","iopub.status.busy":"2024-11-18T01:48:07.51015Z","iopub.status.idle":"2024-11-18T01:48:07.518148Z","shell.execute_reply":"2024-11-18T01:48:07.516829Z","shell.execute_reply.started":"2024-11-18T01:48:07.510513Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.callbacks import LearningRateScheduler\n","def step_decay(epoch):\n","    initial_lr = 0.01\n","    drop = 0.5\n","    epochs_drop = 5\n","    lr = initial_lr * (drop ** (epoch // epochs_drop))\n","    return lr\n","lr_scheduler = LearningRateScheduler(step_decay)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T01:48:07.520132Z","iopub.status.busy":"2024-11-18T01:48:07.519743Z","iopub.status.idle":"2024-11-18T01:48:07.529623Z","shell.execute_reply":"2024-11-18T01:48:07.528365Z","shell.execute_reply.started":"2024-11-18T01:48:07.520089Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.callbacks import ReduceLROnPlateau\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T01:48:07.532117Z","iopub.status.busy":"2024-11-18T01:48:07.531571Z","iopub.status.idle":"2024-11-18T01:48:07.543042Z","shell.execute_reply":"2024-11-18T01:48:07.54174Z","shell.execute_reply.started":"2024-11-18T01:48:07.532057Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.callbacks import EarlyStopping\n","# Define EarlyStopping\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',    # Monitor validation loss\n","    patience=10,            # Number of epochs to wait for improvement\n","    min_delta=0.00001,       # Minimum change to qualify as an improvement\n","    restore_best_weights=True  # Restore weights from the best epoch\n",")\n","\n","if Is_keras:\n","    history = model.fit(\n","        X, y,\n","        epochs=50,\n","        verbose=0,\n","        batch_size=32,\n","        validation_split=0.2,\n","        callbacks=[early_stopping,reduce_lr]\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T01:48:07.545286Z","iopub.status.busy":"2024-11-18T01:48:07.544749Z","iopub.status.idle":"2024-11-18T01:48:07.553338Z","shell.execute_reply":"2024-11-18T01:48:07.552098Z","shell.execute_reply.started":"2024-11-18T01:48:07.545224Z"},"trusted":true},"outputs":[],"source":["if Is_keras:\n","    model.save(\"/kaggle/working/model.keras\")"]},{"cell_type":"markdown","metadata":{},"source":["# Submission\n","\n","See [Jane Street RMF Demo Submission](https://www.kaggle.com/code/ryanholbrook/jane-street-rmf-demo-submission) for details.\n","\n","Depending on the size of your training set, you will need an [inference notebook](https://www.kaggle.com/code/regisvargas/inference-jane-street-a-beginner-s-notebook)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T01:48:07.559435Z","iopub.status.busy":"2024-11-18T01:48:07.55884Z","iopub.status.idle":"2024-11-18T01:48:08.008917Z","shell.execute_reply":"2024-11-18T01:48:08.007714Z","shell.execute_reply.started":"2024-11-18T01:48:07.55939Z"},"trusted":true},"outputs":[],"source":["import os\n","import polars as pl\n","import kaggle_evaluation.jane_street_inference_server"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T01:48:08.010722Z","iopub.status.busy":"2024-11-18T01:48:08.010321Z","iopub.status.idle":"2024-11-18T01:48:08.023351Z","shell.execute_reply":"2024-11-18T01:48:08.022054Z","shell.execute_reply.started":"2024-11-18T01:48:08.010682Z"},"trusted":true},"outputs":[],"source":["import polars as pl\n","import numpy as np\n","# Assuming `model` is your trained model\n","# Assuming features required by the model are named 'feature_00', 'feature_01', etc.\n","def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n","    \"\"\"Make a prediction.\"\"\"\n","    global lags_\n","    if lags is not None:\n","        lags_ = lags\n","    # Extract the features for the model input\n","    feature_columns = [col for col in test.columns if col.startswith(\"feature_\")]\n","    features = test.select(feature_columns).to_numpy()  # Convert to numpy array for model input\n","    features = np.nan_to_num(features, nan=0.0, posinf=0.0, neginf=0.0)\n","    # Generate predictions using the model\n","    #model_predictions = model.predict(features)\n","    if Is_keras:\n","        responder_6_predictions = model.predict(features)[:,0]\n","    else:\n","        responder_6_predictions = model_xgb.predict(features)\n","   # print(responder_6_predictions)    \n","    #responder_6_predictions = model_predictions[:, 6]  # Assuming responder_6 is at index 6\n","    # Create a new Polars DataFrame with row_id and responder_6 predictions\n","    predictions = test.select(\"row_id\").with_columns(\n","        pl.Series(\"responder_6\", responder_6_predictions)\n","    )\n","    print(predictions)\n","    # Ensure the output format and length requirements\n","    if isinstance(predictions, pl.DataFrame):\n","        assert predictions.columns == ['row_id', 'responder_6']\n","    elif isinstance(predictions, pd.DataFrame):\n","        assert (predictions.columns == ['row_id', 'responder_6']).all()\n","    else:\n","        raise TypeError('The predict function must return a DataFrame')\n","    \n","    assert len(predictions) == len(test)\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-11-18T01:48:08.025333Z","iopub.status.busy":"2024-11-18T01:48:08.024839Z","iopub.status.idle":"2024-11-18T01:48:08.416938Z","shell.execute_reply":"2024-11-18T01:48:08.41564Z","shell.execute_reply.started":"2024-11-18T01:48:08.025287Z"},"trusted":true},"outputs":[],"source":["inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n","if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n","    inference_server.serve()\n","else:\n","    inference_server.run_local_gateway(\n","        (\n","            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n","            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n","        )\n","    )"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":9871156,"sourceId":84493,"sourceType":"competition"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
